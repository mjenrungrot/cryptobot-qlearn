{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T21:22:54.270446Z",
     "start_time": "2018-04-06T21:22:51.994008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teerapatjenrungrot/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T21:22:54.411463Z",
     "start_time": "2018-04-06T21:22:54.273732Z"
    }
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, state_size, is_eval=False, model_name=\"\"):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = 3           # stay, buy, sell\n",
    "        self.memory = deque(maxlen=1000)\n",
    "        self.inventory = []\n",
    "        self.model_name = model_name\n",
    "        self.is_eval = is_eval\n",
    "        \n",
    "        self.gamma = 0.95\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.01\n",
    "        self.epsilon_decay = 0.995\n",
    "        \n",
    "        self.model = load_model(\"models/\" + model_name) if is_eval else self._model()\n",
    "    \n",
    "    def _model(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(units=64, input_dim=self.state_size, activation='relu'))\n",
    "        model.add(Dense(units=32, activation='relu'))\n",
    "        model.add(Dense(units=8 , activation='relu'))\n",
    "        model.add(Dense(self.action_size, activation='linear'))\n",
    "        model.compile(loss='mse', optimizer=Adam(lr=0.001))\n",
    "        \n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        if not self.is_eval and np.random.rand() <= self.epsilon:\n",
    "            # randomize an integer in [0, self.action_size)\n",
    "            return random.randrange(self.action_size)\n",
    "        options = self.model.predict(state)\n",
    "        return np.argmax(options[0])\n",
    "    \n",
    "    def expReplay(self, batch_size):\n",
    "        mini_batch = []\n",
    "        l = len(self.memory)\n",
    "        for i in range(l - batch_size + 1, l):\n",
    "            mini_batch.append(self.memory[i])\n",
    "        for state, action, reward, next_state, done in mini_batch:\n",
    "            target = reward\n",
    "            if not done:\n",
    "                target = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            target_f = self.model.predict(state)\n",
    "            target_f[0][action] = target\n",
    "            self.model.fit(state, target_f, epochs=1, verbose=False)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T21:22:54.421466Z",
     "start_time": "2018-04-06T21:22:54.414772Z"
    }
   },
   "outputs": [],
   "source": [
    "def getStockDataVec(key):\n",
    "    df = pd.read_csv(key + \".csv\")\n",
    "    return df['Close'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T21:22:54.442386Z",
     "start_time": "2018-04-06T21:22:54.425402Z"
    }
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    \"\"\"\n",
    "    Return the sigmoid function of x\n",
    "    \"\"\"\n",
    "    return 1.0 / (1.0 + math.exp(-x))\n",
    "    \n",
    "def getState(data, t, n):\n",
    "    \"\"\"\n",
    "    Return an n-day state representation ending at time t\n",
    "    \"\"\"\n",
    "    d = t - n + 1\n",
    "    block = data[d: t+1] if d >= 0 else np.append(-d * [data[0]], data[0: t + 1]) # pad with t0\n",
    "    res = []\n",
    "    for i in range(n - 1):\n",
    "        res.append(sigmoid(block[i+1] - block[i]))\n",
    "    return np.array([res])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-06T21:22:54.449448Z",
     "start_time": "2018-04-06T21:22:54.444849Z"
    }
   },
   "outputs": [],
   "source": [
    "STOCK_NAME = \"^GSPC\"\n",
    "window_size = 10\n",
    "episode_count = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.060Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent(window_size)\n",
    "data = getStockDataVec(STOCK_NAME)\n",
    "l = len(data) - 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.068Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0/100\n",
      "Buy: 1300.800049\n",
      "Sell: 1313.27002 | Profit: 12.469970999999987\n",
      "Buy: 1329.469971\n",
      "Buy: 1347.969971\n",
      "Sell: 1342.540039 | Profit: 13.070067999999992\n",
      "Buy: 1342.900024\n",
      "Sell: 1364.300049 | Profit: 16.330077999999958\n",
      "Sell: 1357.51001 | Profit: 14.609985999999935\n",
      "Buy: 1332.530029\n",
      "Buy: 1330.310059\n",
      "Buy: 1318.800049\n",
      "Buy: 1315.920044\n",
      "Sell: 1301.530029 | Profit: -31.0\n",
      "Buy: 1278.939941\n",
      "Buy: 1255.27002\n",
      "Buy: 1245.859985\n",
      "Buy: 1267.650024\n",
      "Buy: 1257.939941\n",
      "Buy: 1241.22998\n",
      "Sell: 1241.410034 | Profit: -88.90002499999991\n",
      "Buy: 1253.800049\n",
      "Buy: 1261.890015\n",
      "Buy: 1264.73999\n",
      "Buy: 1197.660034\n",
      "Buy: 1173.560059\n",
      "Buy: 1150.530029\n",
      "Sell: 1170.810059 | Profit: -147.98999000000003\n",
      "Sell: 1142.619995 | Profit: -173.30004899999994\n",
      "Buy: 1122.140015\n",
      "Buy: 1117.579956\n",
      "Buy: 1139.829956\n",
      "Buy: 1152.689941\n",
      "Sell: 1182.170044 | Profit: -96.76989700000013\n",
      "Sell: 1145.869995 | Profit: -109.40002499999991\n",
      "Sell: 1151.439941 | Profit: -94.42004399999996\n",
      "Buy: 1165.890015\n",
      "Sell: 1238.160034 | Profit: -29.489990000000034\n",
      "Sell: 1209.469971 | Profit: -48.4699700000001\n",
      "Buy: 1228.75\n",
      "Buy: 1253.050049\n",
      "Buy: 1249.459961\n",
      "Buy: 1266.439941\n",
      "Buy: 1248.579956\n",
      "Buy: 1263.51001\n",
      "Buy: 1255.540039\n",
      "Sell: 1255.180054 | Profit: 13.950073999999859\n",
      "Buy: 1245.670044\n",
      "Buy: 1248.920044\n",
      "Buy: 1284.98999\n",
      "Buy: 1288.48999\n",
      "Buy: 1291.959961\n",
      "Buy: 1289.050049\n",
      "Buy: 1293.170044\n",
      "Sell: 1277.890015 | Profit: 24.089966000000004\n",
      "Sell: 1248.079956 | Profit: -13.81005899999991\n",
      "Buy: 1255.819946\n",
      "Sell: 1260.670044 | Profit: -4.069946000000073\n",
      "Sell: 1267.109985 | Profit: 69.44995100000006\n",
      "Buy: 1283.569946\n",
      "Buy: 1276.959961\n",
      "Buy: 1264.959961\n",
      "Sell: 1254.390015 | Profit: 80.82995600000004\n",
      "Sell: 1255.849976 | Profit: 105.31994699999996\n",
      "Sell: 1241.599976 | Profit: 119.45996100000002\n",
      "Buy: 1219.869995\n",
      "Buy: 1208.430054\n",
      "Sell: 1212.579956 | Profit: 95.0\n",
      "Sell: 1223.140015 | Profit: 83.31005899999991\n",
      "Buy: 1237.040039\n",
      "Sell: 1225.349976 | Profit: 72.66003499999988\n",
      "Sell: 1218.599976 | Profit: 52.70996100000002\n",
      "Buy: 1216.76001\n",
      "Buy: 1226.199951\n",
      "Sell: 1224.380005 | Profit: -4.369995000000017\n",
      "Sell: 1236.719971 | Profit: -16.330077999999958\n",
      "Sell: 1219.23999 | Profit: -30.219970999999987\n",
      "Sell: 1190.589966 | Profit: -75.84997500000009\n",
      "Sell: 1198.780029 | Profit: -49.799927000000025\n",
      "Sell: 1180.180054 | Profit: -83.32995600000004\n",
      "Sell: 1208.140015 | Profit: -47.40002400000003\n",
      "Sell: 1215.680054 | Profit: -29.989990000000034\n",
      "Sell: 1202.449951 | Profit: -46.470092999999906\n",
      "Sell: 1214.439941 | Profit: -70.55004899999994\n",
      "Sell: 1215.02002 | Profit: -73.4699700000001\n",
      "Buy: 1171.650024\n",
      "Sell: 1205.819946 | Profit: -86.14001499999995\n",
      "Sell: 1204.52002 | Profit: -84.53002900000001\n",
      "Sell: 1211.22998 | Profit: -81.9400639999999\n",
      "Buy: 1215.930054\n",
      "Sell: 1220.75 | Profit: -35.06994600000007\n",
      "Sell: 1214.349976 | Profit: -69.2199700000001\n",
      "Sell: 1200.47998 | Profit: -76.47998099999995\n",
      "Sell: 1183.530029 | Profit: -81.42993200000001\n",
      "Buy: 1183.430054\n",
      "Sell: 1190.160034 | Profit: -29.70996100000002\n",
      "Buy: 1186.72998\n",
      "Sell: 1178.02002 | Profit: -30.410033999999996\n",
      "Buy: 1181.660034\n",
      "Buy: 1161.969971\n",
      "Buy: 1171.410034\n",
      "Buy: 1157.26001\n",
      "Buy: 1165.310059\n",
      "Sell: 1162.089966 | Profit: -74.95007299999997\n",
      "Buy: 1179.209961\n",
      "Buy: 1161.51001\n",
      "Buy: 1148.560059\n",
      "Sell: 1129.030029 | Profit: -87.72998099999995\n",
      "Sell: 1133.579956 | Profit: -92.61999500000002\n",
      "Buy: 1132.939941\n",
      "Sell: 1131.73999 | Profit: -39.910033999999996\n",
      "Sell: 1085.780029 | Profit: -130.1500249999999\n",
      "Buy: 1092.540039\n",
      "Sell: 1038.77002 | Profit: -144.660034\n",
      "Sell: 1032.73999 | Profit: -153.98999000000003\n",
      "Sell: 1016.099976 | Profit: -165.56005800000003\n",
      "Sell: 984.5399779999999 | Profit: -177.42999300000008\n",
      "Sell: 965.7999880000001 | Profit: -205.6100459999999\n",
      "Sell: 1003.4500119999999 | Profit: -153.80999800000006\n",
      "Sell: 1012.2700199999999 | Profit: -153.04003899999998\n",
      "Sell: 1007.0399779999999 | Profit: -172.16998300000012\n",
      "Sell: 1018.6099849999999 | Profit: -142.90002500000003\n",
      "Sell: 1040.939941 | Profit: -107.62011799999982\n",
      "Sell: 1038.550049 | Profit: -94.38989200000015\n",
      "Sell: 1051.329956 | Profit: -41.21008299999994\n",
      "Buy: 1062.439941\n",
      "Sell: 1056.75 | Profit: -5.68994100000009\n",
      "Buy: 1104.609985\n",
      "Sell: 1078.300049 | Profit: -26.309936000000107\n",
      "Buy: 1059.780029\n",
      "Sell: 1118.859985 | Profit: 59.07995600000004\n",
      "Buy: 1141.209961\n",
      "Buy: 1137.030029\n",
      "Sell: 1150.339966 | Profit: 9.130004999999983\n",
      "Sell: 1149.5 | Profit: 12.469970999999987\n",
      "Buy: 1128.52002\n",
      "Sell: 1140.199951 | Profit: 11.679931000000124\n",
      "Buy: 1139.930054\n",
      "Sell: 1136.76001 | Profit: -3.1700439999999617\n",
      "Buy: 1142.920044\n",
      "Buy: 1149.560059\n",
      "Buy: 1139.930054\n",
      "Sell: 1144.890015 | Profit: 1.9699709999999868\n",
      "Sell: 1144.650024 | Profit: -4.91003499999988\n",
      "Sell: 1149.369995 | Profit: 9.43994100000009\n",
      "Buy: 1165.27002\n",
      "Sell: 1172.51001 | Profit: 7.239990000000034\n",
      "Buy: 1156.550049\n",
      "Sell: 1145.599976 | Profit: -10.950072999999975\n",
      "Buy: 1138.880005\n",
      "Buy: 1127.579956\n",
      "Sell: 1119.310059 | Profit: -19.569946000000073\n",
      "Buy: 1128.180054\n",
      "Buy: 1132.150024\n",
      "Buy: 1133.280029\n",
      "Buy: 1133.060059\n",
      "Buy: 1100.640015\n",
      "Buy: 1113.569946\n",
      "Buy: 1130.199951\n",
      "Sell: 1094.439941 | Profit: -33.14001499999995\n",
      "Sell: 1090.02002 | Profit: -38.160033999999996\n",
      "Sell: 1083.51001 | Profit: -48.640014000000065\n",
      "Sell: 1080.170044 | Profit: -53.10998500000005\n",
      "Sell: 1096.219971 | Profit: -36.84008799999992\n",
      "Sell: 1111.939941 | Profit: 11.299926000000141\n",
      "Buy: 1107.5\n",
      "Sell: 1118.51001 | Profit: 4.940063999999893\n",
      "Sell: 1116.47998 | Profit: -13.719970999999987\n",
      "Sell: 1104.180054 | Profit: -3.3199460000000727\n"
     ]
    }
   ],
   "source": [
    "for e in range(episode_count + 1):\n",
    "    print(\"Episode {:}/{:}\".format(e, episode_count))\n",
    "    state = getState(data, 0, window_size+1)\n",
    "    total_profit = 0\n",
    "    agent.inventory = []\n",
    "    \n",
    "    for t in range(l):\n",
    "        action = agent.act(state)\n",
    "        \n",
    "        # Sit\n",
    "        next_state = getState(data, t+1, window_size+1)\n",
    "        reward = 0\n",
    "\n",
    "        # Buy action\n",
    "        if action == 1:\n",
    "            agent.inventory.append(data[t])\n",
    "            print(\"Buy: {:}\".format(data[t]))\n",
    "\n",
    "        # Sell action\n",
    "        elif action == 2 and len(agent.inventory) > 0:\n",
    "            bought_price = agent.inventory.pop(0)\n",
    "            reward = max(data[t] - bought_price, 0)\n",
    "            total_profit += data[t] - bought_price\n",
    "            print(\"Sell: {:} | Profit: {:}\".format(data[t], data[t] - bought_price))\n",
    "\n",
    "        done = True if t == l-1 else False\n",
    "        agent.memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "\n",
    "        if done:\n",
    "            print(\"------------------------------------\")\n",
    "            print(\"Total Profit: {:}\".format(total_profit))\n",
    "            print(\"------------------------------------\")\n",
    "    \n",
    "        if len(agent.memory) > batch_size:\n",
    "            agent.expReplay(batch_size)\n",
    "    \n",
    "    if e % 10 == 0:\n",
    "        agent.model.save(\"models/model_ep\" + str(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.110Z"
    }
   },
   "outputs": [],
   "source": [
    "STOCK_NAME = \"^GSPC\"\n",
    "model_name = 'model_ep0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.113Z"
    }
   },
   "outputs": [],
   "source": [
    "model = load_model(\"models/\" + model_name)\n",
    "window_size = model.layers[0].input.shape.as_list()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.116Z"
    }
   },
   "outputs": [],
   "source": [
    "agent = Agent(window_size, True, model_name)\n",
    "data = getStockDataVec(STOCK_NAME)\n",
    "l = len(data) - 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.120Z"
    }
   },
   "outputs": [],
   "source": [
    "state = getState(data, 0, window_size + 1)\n",
    "total_profit = 0\n",
    "agent.inventory = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-06T21:22:52.122Z"
    }
   },
   "outputs": [],
   "source": [
    "for t in range(l):\n",
    "    action = agent.act(state)\n",
    "    \n",
    "    # Sit \n",
    "    next_state = getState(data, t+1, window_size+1)\n",
    "    reward = 0\n",
    "    \n",
    "    # Buy action\n",
    "    if action == 1:\n",
    "        agent.inventory.append(data[t])\n",
    "        print(\"Buy: {:}\".format(data[t]))\n",
    "\n",
    "    # Sell action\n",
    "    elif action == 2 and len(agent.inventory) > 0:\n",
    "        bought_price = agent.inventory.pop(0)\n",
    "        reward = max(data[t] - bought_price, 0)\n",
    "        total_profit += data[t] - bought_price\n",
    "        print(\"Sell: {:} | Profit: {:}\".format(data[t], data[t] - bought_price))\n",
    "\n",
    "    done = True if t == l-1 else False\n",
    "    agent.memory.append((state, action, reward, next_state, done))\n",
    "    state = next_state\n",
    "\n",
    "    if done:\n",
    "        print(\"------------------------------------\")\n",
    "        print(\"Total Profit: {:}\".format(total_profit))\n",
    "        print(\"------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
